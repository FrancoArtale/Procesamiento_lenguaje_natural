# Desaf铆os de procesamiento del lenguaje natural

Especializaci贸n en IA - UBA (Universidad Nacional de Buenos Aires) - Projectos finales

### Desaf铆o 1:

En el primer desaf铆o, se abordaron los fundamentos de la vectorizaci贸n de texto, utilizando posteriormente un modelo de clasificaci贸n como Na茂ve Bayes para encontrar similitudes entre textos. Para ello, se emple贸 el conjunto de datos _20 Newsgroups_ de scikit-learn.

Para la vectorizaci贸n se siguieron los siguientes pasos:
1. Se instanci贸 un vectorizador.
2. Se entren贸 el vectorizador.

Para valorar la similitud entre texto se uso la similitud del coseno.

Luego se optimizaron estos modelo para lograr el maximo valor de la metrica F1-score. El mejor valor obtenido fue de 0.77.

Por ultimo se invirtio la matriz documento-t茅rmino para estudiar similitudes entre palabras. En la siguiente figura se puede ver un ejemplo de predicciones de palabras similares:

![Predicciones de palabras](desafio1_similitud_palabras.png)

### Desaf铆o 2:

A partir de un dataset (corpus), se crearon vectores de palabras (embeddings) utilizando la biblioteca Gensim. Los vectores fueron graficados para observar las similitudes en el espacio de embeddings. Finalmente, se plantearon pruebas de analog铆as.

El dataset utilizado fue la Biblia del proyecto Gutenberg, la cual fue preprocesada antes de crear los vectores. El preprocesamiento incluy贸 los siguientes pasos:
1. Lematizaci贸n.
2. Eliminaci贸n de los signos de puntuaci贸n.
3. Filtrado las _stropwords_.
Para generar los vectores, se utiliz贸 un modelo Word2Vec. Posteriormente, el modelo generador de vectores fue entrenado durante 100 茅pocas.

En la siguiente figura, se pueden ver resultados similares usando la similitud coseno de la palabra _god_:

![image](https://github.com/user-attachments/assets/1dbfa956-efd8-409d-bd85-27ddeae0a70c)

En la siguiente figura, se pueden observar los resultados menos similares de la palabra _prayer_:

![image2](https://github.com/user-attachments/assets/09d24eab-a47d-448b-9269-7df7e7b2af5d)

En la siguiente imagen, se muestra la distribuci贸n de los vectores en el espacio de embeddings:

![image3](https://github.com/user-attachments/assets/d8153e05-3012-4bfa-8026-c942529704c7)

En el gr谩fico, podemos ver que las palabras "David" y "altar" est谩n muy cerca entre s铆. Seg煤n la Biblia, David construy贸 un altar e hizo sacrificios all铆, lo que podr铆a explicar esta relaci贸n que se observa en el gr谩fico.

En el gr谩fico tambi茅n se puede apreciar una cercan铆a entre "seven" y "priest" (sacerdote). Esto tal vez se deba a los siete sacramentos, de los cuales la mayor铆a solo puede ser administrada por un sacerdote.

Asimismo, "water" y "sea" est谩n cercanos.

Uno de los tests de analog铆as que se realiz贸 fue: "orador" es a "Dios" como "sacrificio" es a "altar", con el fin de obtener palabras relacionadas con "altar". Sin embargo, se obtuvieron resultados m谩s cercanos a "sacrificio". En la siguiente imagen se puede ver lo obtenido:

![image](https://github.com/user-attachments/assets/f00edb48-5c59-4b07-b0bf-a5c62438300e)

### Desaf铆o 3:

Se entrenaron modelos de lenguaje con tokenizaci贸n por caracteres y por palabras. Estos modelos se utilizaron para la generaci贸n de secuencias. Para la generaci贸n, se emplearon tanto la predicci贸n m谩s probable como m茅todos como Beam Search y muestreo aleatorio para armar las secuencias.

El dataset (corpus) utilizado en este caso fue el libro Viaje al centro de la Tierra de Julio Verne, descargado del proyecto Gutenberg.

Preprocesamiento de datos:
1. Tokenizaci贸n del libro.
2. Separamos las sentencias en un larog de 100 caracteres o palabras seg煤n el modelo.
3. Separaci贸n en entrenamiento y validaci贸n.

Para el entrenamiento se utiliz贸 la metrica de perplejidad, las arquitecturas utilizadas fueron RNN, LSTM Y GRU, todos entrenados durante 20 epocas.

En la siguiente figura se puede ver el rendimiento de las distintas arquitecturas en el caso de tokenizaci贸n por caracteres:

![image](https://github.com/user-attachments/assets/1a90ba5e-6eab-4418-95dc-ba02cc20ba57)

En la siguiente figura se puede ver el rendimiento de las distintas arquitecturas en el caso de tokenizaci贸n por palabras:

![image](https://github.com/user-attachments/assets/c1c120da-4961-4b7e-9531-48f06f8a3236)

En la siguiente figura se puede ver las predicciones de las distintas arquitecturas en el caso de tokenizaci贸n por caracteres:

![image](https://github.com/user-attachments/assets/dfc5c4dc-2485-4292-a3fa-113424b11e98)


En la siguiente figura se puede ver las predicciones de las distintas arquitecturas en el caso de tokenizaci贸n por palabras:

![image](https://github.com/user-attachments/assets/43aefdf7-8628-427c-92ec-a88364aa1bae)

### Desaf铆o 4:


## Muchas gracias!
Sientete libre de contactarte por mail a francoa23@gmail.com por cualquier duda.
Disfruta !!
