{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq6j8LsYq1Dr"
      },
      "source": [
        "### Vectorización de texto y modelo de clasificación Naïve Bayes con el dataset 20 newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "id": "l7cXR6CI30ry"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# 20newsgroups por ser un dataset clásico de NLP ya viene incluido y formateado\n",
        "# en sklearn\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD-pVDWV_rQc"
      },
      "source": [
        "## Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ech9qJaUo9vK"
      },
      "outputs": [],
      "source": [
        "# cargamos los datos (ya separados de forma predeterminada en train y test)\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes')) # returns a list of the raw texts that can be fed to text feature extractor, si usamos sklearn.datasets.fetch_20newsgroups_vectorized no hace falta vectorizar, ya viene vectorizado.\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxjSI7su_uWI"
      },
      "source": [
        "## Vectorización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-94VP0QYCzDn"
      },
      "outputs": [],
      "source": [
        "# instanciamos un vectorizador\n",
        "# ver diferentes parámetros de instanciación en la documentación de sklearn\n",
        "tfidfvect = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "ftPlyanuak8n",
        "outputId": "45a94d0e-49e7-4f7c-c806-7d5b66779dd0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.',\n",
              " 11314,\n",
              " ['alt.atheism',\n",
              "  'comp.graphics',\n",
              "  'comp.os.ms-windows.misc',\n",
              "  'comp.sys.ibm.pc.hardware',\n",
              "  'comp.sys.mac.hardware',\n",
              "  'comp.windows.x',\n",
              "  'misc.forsale',\n",
              "  'rec.autos',\n",
              "  'rec.motorcycles',\n",
              "  'rec.sport.baseball',\n",
              "  'rec.sport.hockey',\n",
              "  'sci.crypt',\n",
              "  'sci.electronics',\n",
              "  'sci.med',\n",
              "  'sci.space',\n",
              "  'soc.religion.christian',\n",
              "  'talk.politics.guns',\n",
              "  'talk.politics.mideast',\n",
              "  'talk.politics.misc',\n",
              "  'talk.religion.misc'])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# en el atributo `data` accedemos al texto\n",
        "newsgroups_train.data[0], len(newsgroups_train.data), list(newsgroups_train.target_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1zxcXV6aC_oL"
      },
      "outputs": [],
      "source": [
        "# con la interfaz habitual de sklearn podemos fitear el vectorizador\n",
        "# (obtener el vocabulario y calcular el vector IDF)\n",
        "# y transformar directamente los datos\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "# `X_train` la podemos denominar como la matriz documento-término"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11314, 101631)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tenemos 11314 documentos y 101631 palabras distintas entre los documentos, X_train es una matriz, donde cada vector-fila representa un documento y cada valor del vector representa una palabra, que tan \"importante\" es esa palabra en el documento especifico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Sv7TXbda41-",
        "outputId": "dcca5de6-dac1-4d68-d284-ce7be2ed9e2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n",
            "shape: (11314, 101631)\n",
            "cantidad de documentos: 11314\n",
            "tamaño del vocabulario (dimensionalidad de los vectores): 101631\n"
          ]
        }
      ],
      "source": [
        "# recordar que las vectorizaciones por conteos son esparsas\n",
        "# por ello sklearn convenientemente devuelve los vectores de documentos\n",
        "# como matrices esparsas\n",
        "print(type(X_train))\n",
        "print(f'shape: {X_train.shape}')\n",
        "print(f'cantidad de documentos: {X_train.shape[0]}')\n",
        "print(f'tamaño del vocabulario (dimensionalidad de los vectores): {X_train.shape[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Promedio de componentes que no son ceros en los vectores: 97.54525366802191 de un total de 101631\n"
          ]
        }
      ],
      "source": [
        "print(f\"Promedio de componentes que no son ceros en los vectores: {X_train.nnz / float(X_train.shape[0])} de un total de {X_train.shape[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgydNTZ2pAgR",
        "outputId": "95111464-e40c-4b57-d154-ede153739a82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25775"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# una vez fiteado el vectorizador, podemos acceder a atributos como el vocabulario\n",
        "# aprendido. Es un diccionario que va de términos a índices.\n",
        "# El índice es la posición en el vector de documento.\n",
        "tfidfvect.vocabulary_['car']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "xnTSZuvyrTcP"
      },
      "outputs": [],
      "source": [
        "# es muy útil tener el diccionario opuesto que va de índices a términos\n",
        "idx2word = {v: k for k,v in tfidfvect.vocabulary_.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swa-AgWrMSHM",
        "outputId": "93d09f31-4c42-4215-e750-a13c83ecf96a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# en `y_train` guardamos los targets que son enteros, es el indice de la categoria\n",
        "y_train = newsgroups_train.target\n",
        "y_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je5kxvQMDLvf",
        "outputId": "59799046-9799-406f-c4be-81c5765de58d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clases [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# hay 20 clases correspondientes a los 20 grupos de noticias\n",
        "print(f'clases {np.unique(newsgroups_test.target)}')\n",
        "newsgroups_test.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXCICFSd_y90"
      },
      "source": [
        "## Similaridad de documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pki_olShnyE",
        "outputId": "b2bd8485-40c7-4923-c8a9-4ad6b735576e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "THE WHITE HOUSE\n",
            "\n",
            "                  Office of the Press Secretary\n",
            "                   (Pittsburgh, Pennslyvania)\n",
            "______________________________________________________________\n",
            "For Immediate Release                         April 17, 1993     \n",
            "\n",
            "             \n",
            "                  RADIO ADDRESS TO THE NATION \n",
            "                        BY THE PRESIDENT\n",
            "             \n",
            "                Pittsburgh International Airport\n",
            "                    Pittsburgh, Pennsylvania\n",
            "             \n",
            "             \n",
            "10:06 A.M. EDT\n",
            "             \n",
            "             \n",
            "             THE PRESIDENT:  Good morning.  My voice is coming to\n",
            "you this morning through the facilities of the oldest radio\n",
            "station in America, KDKA in Pittsburgh.  I'm visiting the city to\n",
            "meet personally with citizens here to discuss my plans for jobs,\n",
            "health care and the economy.  But I wanted first to do my weekly\n",
            "broadcast with the American people. \n",
            "             \n",
            "             I'm told this station first broadcast in 1920 when\n",
            "it reported that year's presidential elections.  Over the past\n",
            "seven decades presidents have found ways to keep in touch with\n",
            "the people, from whistle-stop tours to fire-side chats to the bus\n",
            "tour that I adopted, along with Vice President Gore, in last\n",
            "year's campaign.\n",
            "             \n",
            "             Every Saturday morning I take this time to talk with\n",
            "you, my fellow Americans, about the problems on your minds and\n",
            "what I'm doing to try and solve them.  It's my way of reporting\n",
            "to you and of giving you a way to hold me accountable.\n",
            "             \n",
            "             You sent me to Washington to get our government and\n",
            "economy moving after years of paralysis and policy and a bad\n",
            "experiment with trickle-down economics.  You know how important\n",
            "it is for us to make bold, comprehensive changes in the way we do\n",
            "business.  \n",
            "             \n",
            "             We live in a competitive global economy.  Nations\n",
            "rise and fall on the skills of their workers, the competitiveness\n",
            "of their companies, the imagination of their industries, and the\n",
            "cooperative experience and spirit that exists between business,\n",
            "labor and government.  Although many of the economies of the\n",
            "industrialized world are now suffering from slow growth, they've\n",
            "made many of the smart investments and the tough choices which\n",
            "our government has for too long ignored.  That's why many of them\n",
            "have been moving ahead and too many of our people have been\n",
            "falling behind.\n",
            "             \n",
            "             We have an economy today that even when it grows is\n",
            "not producing new jobs.  We've increased the debt of our nation\n",
            "by four times over the last 12 years, and we don't have much to\n",
            "show for it.  We know that wages of most working people have\n",
            "stopped rising, that most people are working longer work weeks\n",
            "and that too many families can no longer afford the escalating\n",
            "cost of health care.\n",
            "             \n",
            "             But we also know that, given the right tools, the\n",
            "right incentives and the right encouragement, our workers and\n",
            "businesses can make the kinds of products and profits our economy\n",
            "needs to expand opportunity and to make our communities better\n",
            "places to live.\n",
            "             \n",
            "             In many critical products today Americans are the\n",
            "low cost, high quality producers.  Our task is to make sure that\n",
            "we create more of those kinds of jobs.\n",
            "             \n",
            "             Just two months ago I gave Congress my plan for\n",
            "long-term jobs and economic growth.  It changes the old\n",
            "priorities in Washington and puts our emphasis where it needs to\n",
            "be -- on people's real needs, on increasing investments and jobs\n",
            "and education, on cutting the federal deficit, on stopping the\n",
            "waste which pays no dividends, and redirecting our precious\n",
            "resources toward investment that creates jobs now and lays the\n",
            "groundwork for robust economic growth in the future.\n",
            "             \n",
            "             These new directions passed the Congress in record\n",
            "time and created a new sense of hope and opportunity in our\n",
            "country.  Then the jobs plan I presented to Congress, which would\n",
            "create hundreds of thousands of jobs, most of them in the private\n",
            "sector in 1993 and 1994, passed the House of Representatives.  It\n",
            "now has the support of a majority of the United States Senate. \n",
            "But it's been held up by a filibuster of a minority in the\n",
            "Senate, just 43 senators.  They blocked a vote that they know\n",
            "would result in the passage of our bill and the creation of jobs.\n",
            "             \n",
            "             The issue isn't politics; the issue is people. \n",
            "Millions of Americans are waiting for this legislation and\n",
            "counting on it, counting on us in Washington.  But the jobs bill\n",
            "has been grounded by gridlock.  \n",
            "             \n",
            "             I know the American people are tired of business as\n",
            "usual and politics as usual.  I know they don't want us to spin\n",
            "or wheels.  They want the recovery to get moving.  So I have\n",
            "taken a first step to break this gridlock and gone the extra\n",
            "mile.  Yesterday I offered to cut the size of this plan by 25\n",
            "percent -- from $16 billion to $12 billion.  \n",
            "             \n",
            "             It's not what I'd hoped for.  With 16 million\n",
            "Americans looking for full-time work, I simply can't let the bill\n",
            "languish when I know that even a compromise bill will mean\n",
            "hundreds of thousands of jobs for our people.  The mandate is to\n",
            "act to achieve change and move the country forward.  By taking\n",
            "this initiative in the face of an unrelenting Senate talkathon, I\n",
            "think we can respond to your mandate and achieve a significant\n",
            "portion of our original goals.\n",
            "             \n",
            "             First, we want to keep the programs as much as\n",
            "possible that are needed to generate jobs and meet human needs,\n",
            "including highway and road construction, summer jobs for young\n",
            "people, immunization for children, construction of waste water\n",
            "sites, and aid to small businesses.  We also want to keep funding\n",
            "for extended unemployment compensation benefits, for people who\n",
            "have been unemployed for a long time because the economy isn't\n",
            "creating jobs.\n",
            "             \n",
            "             Second, I've recommended that all the other programs\n",
            "in the bill be cut across-the-board by a little more than 40\n",
            "percent.\n",
            "             \n",
            "             And third, I've recommended a new element in this\n",
            "program to help us immediately start our attempt to fight against\n",
            "crime by providing $200 million for cities and towns to rehire\n",
            "police officers who lost their jobs during the recession and put\n",
            "them back to work protecting our people.  I'm also going to fight\n",
            "for a tough crime bill because the people of this country need it\n",
            "and deserve it.\n",
            "             \n",
            "             Now, the people who are filibustering this bill --\n",
            "the Republican senators -- say they won't vote for it because it\n",
            "increases deficit spending, because there's extra spending this\n",
            "year that hasn't already been approved.  That sounds reasonable,\n",
            "doesn't it?  Here's what they don't say.  This program is more\n",
            "than paid for by budget cuts over my five-year budget, and this\n",
            "budget is well within the spending limits already approved by the\n",
            "Congress this year.\n",
            "             \n",
            "             It's amazing to me that many of these same senators\n",
            "who are filibustering the bill voted during the previous\n",
            "administration for billions of dollars of the same kind of\n",
            "emergency spending, and much of it was not designed to put the\n",
            "American people to work.  \n",
            "             \n",
            "             This is not about deficit spending.  We have offered\n",
            "a plan to cut the deficit.  This is about where your priorities\n",
            "are -- on people or on politics.  \n",
            "             \n",
            "             Keep in mind that our jobs bill is paid for dollar\n",
            "for dollar.  It is paid for by budget cuts.  And it's the\n",
            "soundest investment we can now make for ourselves and our\n",
            "children.  I urge all Americans to take another look at this jobs\n",
            "and investment program; to consider again the benefits for all of\n",
            "us when we've helped make more American partners working to\n",
            "ensure the future of our nation and the strength of our economy.\n",
            "             \n",
            "             You know, if every American who wanted a job had\n",
            "one, we wouldn't have a lot of the other problems we have in this\n",
            "country today.  This bill is not a miracle, it's a modest first\n",
            "step to try to set off a job creation explosion in this country\n",
            "again.  But it's a step we ought to take.  And it is fully paid\n",
            "for over the life of our budget.\n",
            "             \n",
            "             Tell your lawmakers what you think.  Tell them how\n",
            "important the bill is.  If it passes, we'll all be winners.\n",
            "             \n",
            "             Good morning, and thank you for listening.\n"
          ]
        }
      ],
      "source": [
        "# Veamos similaridad de documentos. Tomemos algún documento\n",
        "idx = 4811\n",
        "print(newsgroups_train.data[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Ssa9bqJ-hA_v"
      },
      "outputs": [],
      "source": [
        "# midamos la similaridad coseno con todos los documentos de train\n",
        "cossim = cosine_similarity(X_train[idx], X_train)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_mDA7p3AzcQ",
        "outputId": "747a3923-4b1c-4e2b-921d-4ebf2b271b00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.        , 0.70930477, 0.67474953, ..., 0.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# podemos ver los valores de similaridad ordenados de mayor a menos\n",
        "np.sort(cossim)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OIhDA1jAryX",
        "outputId": "04ddf3ca-0741-42d7-8bbb-00bb395f7834"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 4811,  6635,  4253, ...,  6385,  1149, 11238])"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# y a qué documentos corresponden\n",
        "np.argsort(cossim)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "hP7qLS4ZBLps"
      },
      "outputs": [],
      "source": [
        "# los 5 documentos más similares:\n",
        "mostsim = np.argsort(cossim)[::-1][1:6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QdJLHPJACvaj",
        "outputId": "926186cf-7d4c-4bd3-927b-ad00bf7f24f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'talk.politics.misc'"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# el documento original pertenece a la clase:\n",
        "newsgroups_train.target_names[y_train[idx]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWy_73epCbFG",
        "outputId": "daf534e5-b2a8-43d4-d05a-9c52b816cf69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n"
          ]
        }
      ],
      "source": [
        "# y los 5 más similares son de las clases:\n",
        "for i in mostsim:\n",
        "  print(newsgroups_train.target_names[y_train[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRoNnKwhBqzq"
      },
      "source": [
        "### Modelo de clasificación Naïve Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "TPM0thDaLk0R",
        "outputId": "bc7fdc3e-d912-4e0c-9d9e-33efc97b46fc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# es muy fácil instanciar un modelo de clasificación Naïve Bayes y entrenarlo con sklearn\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "NrQjzM48Mu4T"
      },
      "outputs": [],
      "source": [
        "# con nuestro vectorizador ya fiteado en train, vectorizamos los textos\n",
        "# del conjunto de test\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_test = newsgroups_test.target\n",
        "y_pred =  clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkGJhetEPdA4",
        "outputId": "232ee2ce-e904-466e-be57-babc1f319029"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.5854345727938506)"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# el F1-score es una metrica adecuada para reportar desempeño de modelos de claificación\n",
        "# es robusta al desbalance de clases. El promediado 'macro' es el promedio de los\n",
        "# F1-score de cada clase. El promedio 'micro' es equivalente a la accuracy que no\n",
        "# es una buena métrica cuando los datasets son desbalanceados\n",
        "f1_score(y_test, y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McArD4rSDR2K"
      },
      "source": [
        "### Consigna del desafío 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1**. Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos.\n",
        "Estudiar los 5 documentos más similares de cada uno. Analizar si tiene sentido la similaridad según el contenido del texto y la etiqueta de clasificación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"A fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\""
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "newsgroups_train.data[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calidad de coincidencias: [0.81589481 0.23763918 0.23197704 0.21962054 0.21844707] e indices de los docs: [  830  7879  5708 10489 11017]\n",
            "Documento original: misc.forsale, Similares: ['misc.forsale', 'rec.autos', 'misc.forsale', 'misc.forsale', 'misc.forsale']\n",
            "ABOUT ORIGINAL DOCUMENT:  Misc. Items for sale:Walkman:  Aiwa Model HS-T30, 1 year old, mint condition, hardly used,           autoreverse, 3 band Equalizer, Super Bass, Dolby Noise Reduction,\n",
            "ABOUT SIMILAR DOCUMENT 830:  Misc. Items for sale:Mount Plate:  Sony Model CPM-203P, mounting plate for Sony portable CD playersfor Portable: plugs into car lighter, snaps onto the bottom of any Sony\n",
            "ABOUT SIMILAR DOCUMENT 7879:  My friend, David Gordon wants to sell his 1989 Honda. Some of the details of the car are as follows:             Five speed             A/c, AM/FM/Cassette stereo\n",
            "ABOUT SIMILAR DOCUMENT 5708:  I have a used Sony D-808K CarDiscman for sale.  I bought it new on June 16, 1992.  It still has the one-year warranty intact. Specifications:Sony's best car discman\t\t\tperfect condition\n",
            "ABOUT SIMILAR DOCUMENT 10489:  *** 10 MONTH OLD POLK SYSTEM FOR SALE ***Excellent condition 10 month old (proof available) Polk Monitor 4.6 bookshelfspeakers are being offered for sale. The are excellent, and sound great. I amgoing for a higher model. So I need to sell these speakers. I paid $250 for\n",
            "ABOUT SIMILAR DOCUMENT 11017:  Auto Logic Panasonic answering machine with dual cassette system. I willinclude cassettes and AC power adaptor. Excellent condition. Asking $30 withaccessories.\n",
            "\n",
            "\n",
            "\n",
            "Calidad de coincidencias: [0.19953226 0.17720182 0.12981801 0.12201546 0.11589651] e indices de los docs: [10480 10966  4930  4964  5273]\n",
            "Documento original: rec.motorcycles, Similares: ['sci.med', 'talk.politics.misc', 'rec.motorcycles', 'misc.forsale', 'comp.sys.mac.hardware']\n",
            "ABOUT ORIGINAL DOCUMENT:  Does anyone have a rear wheel for a PD they'd like to part with?Does anyone know where I might find one salvage?As long as I'm getting the GIVI luggage for Brunnhilde and have\n",
            "ABOUT SIMILAR DOCUMENT 10480:  does anyone know?-- \n",
            "ABOUT SIMILAR DOCUMENT 10966:  does anyone have Prez. Clinton`s e-mail address.thanks a lot  \n",
            "ABOUT SIMILAR DOCUMENT 4930:  This is a periodic posting intended to answer the Frequently AskedQuestion: What is the DoD? It is posted the first of each month, withan expiration time of over a month. Thus, unless your site's newssoftware is ill-mannered, this posting should always be available.This WitDoDFAQ is crossposted to all four rec.motorcycles groups in an\n",
            "ABOUT SIMILAR DOCUMENT 4964:  The subject line says it all -- I'm trying to locate a copy of SPI'sboard game \"War of the Ring.\"  Anyone have a copy with which they arewilling to part?Thanks a million ...\n",
            "ABOUT SIMILAR DOCUMENT 5273:  Does anyone know what hardware is required and where I could find it forsound recording on the  Mac Portable.Thanks\n",
            "\n",
            "\n",
            "\n",
            "Calidad de coincidencias: [0.21192017 0.18888626 0.18659902 0.17539023 0.16267878] e indices de los docs: [2341 6811 3145 3468 8931]\n",
            "Documento original: rec.sport.hockey, Similares: ['comp.graphics', 'rec.sport.baseball', 'rec.motorcycles', 'comp.graphics', 'misc.forsale']\n",
            "ABOUT ORIGINAL DOCUMENT:  Hi there, I can't seem to get mail to you. Can you tell me your entireadress, or even your dotted decimal address?   (ie. 131.202.3.10)\n",
            "ABOUT SIMILAR DOCUMENT 2341:  I aparantly mistyped the address for the ftp site which holds the images. Thecorrect address should be:jupiter.csd.unb.ca                ^^\n",
            "ABOUT SIMILAR DOCUMENT 6811:  Doug, those stats are great!  they help immensely.  I tried to E-Mailyou with some comments on them but my mail server does not recognizeyour address.  Could you E-Mail me with some info on how to get E-Mailto you?  Thanks!\n",
            "ABOUT SIMILAR DOCUMENT 3145:  There is a new DoD listing. To get a copy use one of these commands:\t\tfinger motohead@cs.colorado.edu\t\t\t\tOR\t\tmail motohead@cs.colorado.edu\n",
            "ABOUT SIMILAR DOCUMENT 3468:  please tell me where you where you FTP'd this from? I would like to havea copy of it. (I would have mailed you, but your post indicates you have no mailaddress...)\n",
            "ABOUT SIMILAR DOCUMENT 8931:  Hey, I can't send mail to you, so....Could you please resend me your address?  I lost it (for H. inMoscow)\n",
            "\n",
            "\n",
            "\n",
            "Calidad de coincidencias: [0.3438439  0.28838006 0.23741125 0.22830641 0.21925259] e indices de los docs: [7493 4891 8116 9527 7542]\n",
            "Documento original: sci.med, Similares: ['sci.med', 'sci.med', 'sci.med', 'sci.med', 'sci.med']\n",
            "ABOUT ORIGINAL DOCUMENT:  A friend has what is apparently a fairly minor case of Crohn'sdisease.But she can't seem to eat certain foods, such as fresh vegetables,without discomfort, and of course she wants to avoid a recurrence.\n",
            "ABOUT SIMILAR DOCUMENT 7493:  If she is having problems with fresh vegetables, the guess is that thereis some obstruction of the intestine.  Without knowing more it is notpossible to say whether the obstruction is permanent due to scarring,or temporary due to swelling of inflammed intestine.  In general, there are\n",
            "ABOUT SIMILAR DOCUMENT 4891:  All your friend really has to do is find a Registered Dietician(RD).  While most work in hospitals and clinics, many major cities will have RD's who are in \"private practice\" so to speak.  Many physicans will refer their patients with Crohn's disease to RD's for dietary help.  If you can get \n",
            "ABOUT SIMILAR DOCUMENT 8116:  Summary of thread:A person has Crohns, raw vegetables cause problems (unspecified)Steve Holland replies:  patient may have mild obstruction.  Avoid thingsthat would plug her up.  Crohn's has no dietary restriction in general.\n",
            "ABOUT SIMILAR DOCUMENT 9527:  Hi,I've just returned from a visit with my OB/GYN and I have a few concerns that maybe y'all can help me with.  I've been seeing her every 4 weeks for the past few months (I'm at week 28) \n",
            "ABOUT SIMILAR DOCUMENT 7542:  A friend of mine is having some symptoms and has asked me to postthe following information.A few weeks ago, she noticed that some of her hair was startingto fall out.  She would touch her head and strands of hair would\n",
            "\n",
            "\n",
            "\n",
            "Calidad de coincidencias: [0.55348062 0.20097519 0.15509999 0.15486069 0.15189523] e indices de los docs: [ 8312 10597  3410  7972  6151]\n",
            "Documento original: sci.crypt, Similares: ['sci.crypt', 'comp.os.ms-windows.misc', 'sci.crypt', 'comp.windows.x', 'comp.windows.x']\n",
            "ABOUT ORIGINAL DOCUMENT:  I've been asked to supply more specific directionsfor automated fetching of the source and documentationfor \"agrep,\" the powerful similarity pattern matching tool.It is at\n",
            "ABOUT SIMILAR DOCUMENT 8312:  A Unix tool of cryptographic significance is availablefor anonymous ftp.\"agrep 2.0.4\" -- a fast approximate pattern-matching tool\n",
            "ABOUT SIMILAR DOCUMENT 10597:  Is there any one know:What is the FTP tool for Windows and where to get the tool ?Thanks for any help !!\n",
            "ABOUT SIMILAR DOCUMENT 3410:  Archive-name: net-privacy/part3Last-modified: 1993/3/3Version: 2.1\n",
            "ABOUT SIMILAR DOCUMENT 7972:  Archive-name: x-faq/part4Last-modified: 1993/04/04----------------------------------------------------------------------Subject:  80)! Where can I get an X-based plotting program?\n",
            "ABOUT SIMILAR DOCUMENT 6151:  Archive-name: x-faq/part2Last-modified: 1993/04/04----------------------------------------------------------------------Subject:  24)! How do I make a screendump or print my application?\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# creamos todos los idx posibles\n",
        "idxs = range(len(newsgroups_train.data))\n",
        "\n",
        "# tomamos 5 indices al azar\n",
        "five_idxs = np.random.choice(idxs, 5)\n",
        "\n",
        "# recorremos los indices:\n",
        "for id in five_idxs:\n",
        "    # calculamos las similitudes\n",
        "    cossim = cosine_similarity(X_train[id], X_train)[0]\n",
        "\n",
        "    # indices de los 5 docs mas similares:\n",
        "    similar_docs_idx_list = np.argsort(cossim)[::-1][1:6]\n",
        "\n",
        "    # Etiquete de clasificación de los documentos similares:\n",
        "    type_similar_document_list = [newsgroups_train.target_names[y_train[i]] for i in similar_docs_idx_list]\n",
        "\n",
        "    # Imprimimos la calidad de las coincidencias y los indices de los docs \n",
        "    print(f\"Calidad de coincidencias: {np.sort(cossim)[::-1][1:6]} e indices de los docs: {similar_docs_idx_list}\")\n",
        "\n",
        "    print(f\"Documento original: {newsgroups_train.target_names[y_train[id]]}, Similares: {type_similar_document_list}\")\n",
        "\n",
        "    # imprimimos algunas lineas de cada documentos para ver si tienen algo en común\n",
        "    original_document_lines = newsgroups_train.data[id].split('\\n')\n",
        "    some_original_document_lines = \"\".join(original_document_lines[:5])\n",
        "    print(\"ABOUT ORIGINAL DOCUMENT: \", some_original_document_lines)\n",
        "    for idx in similar_docs_idx_list:\n",
        "\n",
        "        lines = newsgroups_train.data[idx].split('\\n')\n",
        "\n",
        "        some_lines = \"\".join(lines[:5])\n",
        "\n",
        "        print(f\"ABOUT SIMILAR DOCUMENT {idx}: \", some_lines)\n",
        "\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mayor valor que devuelve la coincidencia de coseno, mayor coincidencia tienen los documentos.  \n",
        "Por ejemplo en el primer caso, hay altos valores devuelto por la coincidencia de coseno, y todos los documentos devueltos hablan sobre ventas.  \n",
        "En el segundo caso, no hay buenos valores devueltos, y los documentos no son tan similares entre sí."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2**. Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación\n",
        "(f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros\n",
        "de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial\n",
        "y ComplementNB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Primer caso: MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.6664185318178519)"
            ]
          },
          "execution_count": 256,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Instanciamos un vectorizador:\n",
        "tfidfvect = TfidfVectorizer(strip_accents=None, \n",
        "                            lowercase=True, \n",
        "                            analyzer=\"word\", \n",
        "                            ngram_range=(1, 1),\n",
        "                            norm=\"l2\",\n",
        "                            sublinear_tf=False,\n",
        "                            )\n",
        "\n",
        "# Aplicamos la vectorización a los distintos datsets:\n",
        "X_train= tfidfvect.fit_transform(newsgroups_train.data)\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_train = newsgroups_train.target\n",
        "y_test = newsgroups_test.target\n",
        "\n",
        "# Creamos y entrenamos el modelo\n",
        "clf = MultinomialNB(alpha=0.1,\n",
        "                    fit_prior=False, \n",
        "                    )\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Hacemos la predicciones y calculamos el F1-score\n",
        "y_pred =  clf.predict(X_test)\n",
        "f1_score(y_test, y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vectorizador:  \n",
        "- Caso sin tocar parametros: np.float64(0.5854345727938506).  \n",
        "- Cambiar strip_accents no afecto en nada, se obtuvo lo mismo.  \n",
        "- lowercase=False redujo: np.float64(0.563325189561675).   \n",
        "- analyzer=\"char_wb\" o \"char\" redujo: np.float64(0.10050507899086067).  \n",
        "- ngram_range=(2, 2) o (1, 2) o (2, 3) redujo: np.float64(0.44465359773367946).  \n",
        "- norm=\"l1\" redujo a: np.float64(0.4949628779936094).\n",
        "- sublinear_tf=True, redujo: np.float64(0.6166664953246763).\n",
        "\n",
        "Modelo:  \n",
        "- Reducir alpha mejora la metrica F1.\n",
        "- cambia fit_prior=False mejora un poco.  \n",
        "\n",
        "Logramos mejorar casi un 10% la calidad inicial del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Segundo caso: ComplementNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.6947966110126378)"
            ]
          },
          "execution_count": 257,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Instanciamos un vectorizador:\n",
        "tfidfvect = TfidfVectorizer(strip_accents=None,\n",
        "                            lowercase=True,\n",
        "                            analyzer=\"word\",\n",
        "                            ngram_range=(1, 1),\n",
        "                            norm=\"l2\",\n",
        "                            sublinear_tf=True\n",
        "                            )\n",
        "\n",
        "# Aplicamos la vectorización a los distintos datsets:\n",
        "X_train= tfidfvect.fit_transform(newsgroups_train.data)\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_train = newsgroups_train.target\n",
        "y_test = newsgroups_test.target\n",
        "\n",
        "# Creamos y entrenamos el modelo\n",
        "clf = ComplementNB(alpha= 0.6,\n",
        "                   fit_prior=True,\n",
        "                   norm=False\n",
        "                    )\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Hacemos la predicciones y calculamos el F1-score\n",
        "y_pred =  clf.predict(X_test)\n",
        "f1_score(y_test, y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Sin tocar ningún parametro: np.float64(0.692953349950875).\n",
        "\n",
        "Vectorizador:  \n",
        "- Cambiar strip_accents no afecto en nada, se obtuvo lo mismo.  \n",
        "- lowercase=False redujo: np.float64(0.6892731374398724).   \n",
        "- analyzer=\"char_wb\" o \"char\" redujo: np.float64(0.12122769736189094).  \n",
        "- ngram_range=(2, 2) o (1, 2) o (2, 3) redujo: np.float64(0.5567051871233293). \n",
        "- norm=\"l1\" redujo a: np.float64(0.6657036625279055).\n",
        "- sublinear_tf=True, mejoro: np.float64(0.6951325517946223).\n",
        "\n",
        "Modelo:\n",
        "- Reducir alpha mejoro algo: np.float64(0.6965218464867293).\n",
        "- Cambiar fit_prior no tuvo cambios.\n",
        "- norm=True redujo la metrica: np.float64(0.6925625135005732).\n",
        "\n",
        "Mejoramos un 12% en comparación al caso inicial de usar el modelo MultinomialNB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Todo lo anterior fue hecho manualmente, esto también se puede hacer con una grilla:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
            "Mejores parámetros: {'alpha': 0.3, 'fit_prior': True, 'norm': False}\n",
            "Mejor score: 0.7667088131250549\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "np.float64(0.6989825595098211)"
            ]
          },
          "execution_count": 258,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creamos la instancia del vectorizador\n",
        "tfidfvect = TfidfVectorizer(strip_accents=None,\n",
        "                            lowercase=True,\n",
        "                            analyzer=\"word\",\n",
        "                            ngram_range=(1, 1),\n",
        "                            norm=\"l2\",\n",
        "                            sublinear_tf=True)\n",
        "\n",
        "# Aplicamos la vectorización a los distintos datsets:\n",
        "X_train= tfidfvect.fit_transform(newsgroups_train.data)\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_train = newsgroups_train.target\n",
        "y_test = newsgroups_test.target\n",
        "\n",
        "# Creamos y entrenamos el modelo\n",
        "clf = ComplementNB()\n",
        "\n",
        "# creamos el mapa de grilla\n",
        "grid_map = {\n",
        "    'alpha': [0.1, 0.2, 0.3, 0.4, 0.7, 0.9, 1, 2, 5, 10],\n",
        "    'fit_prior': [True, False],\n",
        "    'norm': [True, False]\n",
        "}\n",
        "\n",
        "# creamos la grilla\n",
        "grid = GridSearchCV(\n",
        "    estimator=clf,\n",
        "    param_grid=grid_map,\n",
        "    scoring=\"f1_macro\",\n",
        "    n_jobs=-1,\n",
        "    refit=True,\n",
        "    cv=5,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# aplicamos la grilla\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Evaluar los resultados\n",
        "print(f\"Mejores parámetros: {grid.best_params_}\")\n",
        "print(f\"Mejor score: {grid.best_score_}\")\n",
        "\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "# Hacemos la predicciones y calculamos el F1-score\n",
        "y_pred =  best_model.predict(X_test)\n",
        "f1_score(y_test, y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJgf6GQIIEH1"
      },
      "source": [
        "**3**. Transponer la matriz documento-término. De esa manera se obtiene una matriz\n",
        "término-documento que puede ser interpretada como una colección de vectorización de palabras.\n",
        "Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hasta el momento tenemos una matriz donde las filas representan los documentos y las columnas representan las palabras. Transponer significa que las filas representaran a las palabras y las columnas a los documentos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((101631, 11314), (11314, 101631))"
            ]
          },
          "execution_count": 259,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_transpose = X_train.T\n",
        "\n",
        "X_train_transpose.shape, X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20496"
            ]
          },
          "execution_count": 298,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Para buscar los indices de palabras\n",
        "tfidfvect.vocabulary_['authoratative']\n",
        "\n",
        "# car --> indice 25775\n",
        "# photographer --> indice 71223\n",
        "# authoratative --> indice 20496\n",
        "# administrators --> indice 16907\n",
        "# librarian --> indice 56601\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['car', 'photographer', 'authoratative', 'administrators', 'librarian'],\n",
              " [25775, 71223, 20496, 16907, 56601])"
            ]
          },
          "execution_count": 299,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# almacenamos las palabras en una lista\n",
        "words_list = [idx2word[25775], idx2word[71223], idx2word[20496], idx2word[16907], idx2word[56601]]\n",
        "idx_list = [tfidfvect.vocabulary_['car'], tfidfvect.vocabulary_['photographer'], tfidfvect.vocabulary_['authoratative'], tfidfvect.vocabulary_['administrators'], tfidfvect.vocabulary_['librarian']]\n",
        "\n",
        "words_list, idx_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Para car las palabras similares son: \n",
            "cars\n",
            "dealer\n",
            "owner\n",
            "civic\n",
            "the\n",
            "\n",
            "\n",
            "\n",
            "Para photographer las palabras similares son: \n",
            "meskhetians\n",
            "azerbaijanians\n",
            "rasulzade\n",
            "inhumanly\n",
            "westernizers\n",
            "\n",
            "\n",
            "\n",
            "Para authoratative las palabras similares son: \n",
            "legitimacy\n",
            "scintific\n",
            "unscintific\n",
            "woring\n",
            "inself\n",
            "\n",
            "\n",
            "\n",
            "Para administrators las palabras similares son: \n",
            "confusingly\n",
            "pornographic\n",
            "manifestation\n",
            "broadcasting\n",
            "adminstrators\n",
            "\n",
            "\n",
            "\n",
            "Para librarian las palabras similares son: \n",
            "residual\n",
            "actrix\n",
            "progression\n",
            "textbook\n",
            "weakness\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# recorremos los indices:\n",
        "for id in idx_list:\n",
        "    # calculamos las similitudes\n",
        "    cossim = cosine_similarity(X_train_transpose[id], X_train_transpose)[0]\n",
        "\n",
        "    # indices de las 5 palabras mas similares:\n",
        "    similar_words_idx_list = np.argsort(cossim)[::-1][1:6]\n",
        "\n",
        "    print(f\"Para {idx2word[id]} las palabras similares son: \")\n",
        "    for i in similar_words_idx_list:\n",
        "        print(f\"{idx2word[i]}\")\n",
        "\n",
        "    print(\"\\n\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
